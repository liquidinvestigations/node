[cluster]
nomad_url = http://10.66.60.1:4646
consul_url = http://10.66.60.1:8500
vault_url = http://10.66.60.1:8200

# Path to ini file with vault secrets.
vault_secrets = ../cluster/var/vault-secrets.ini
consul_socket = ../cluster/var/consul.socket

[liquid]
# Domain for the liquid bundle.
domain = liquid.example.org

# User-friendly title.
# Defaults to the domain with no spaces, capitalized.
title = Liquid Example Org

# Always serving http. With https enabled, this redirects.
http_port = 80

# Set all applications in debug mode.
# Please
#        do
#           not
#               use
#                   in
#                      production.
debug = true

# Mount liquidinvestigations and hoover repositories.
mount_local_repos = false

# Path to a directory that contains clones of search and snoop.
# Defaults to ./repos/hoover
; hoover_repos_path = /path/to/hoover_org

# Path to a directory that contains a clone of liquidinvestigations/core.
# Defaults to ./repos/liquidinvestigations
; liquidinvestigations_repos_path = /path/to/liquidinvestigations_org

# Directory where docker volumes are mounted.
# This flag is used for import/export operations and checking if a collection
# has been initialized or not, so take care in setting it to the value of the
# Nomad Client meta flag "liquid_volumes".
; volumes = /path/to/volumes

# Defaults to ./collections
; collections = /path/to/collections

# Allow only staff to log in (e.g. during maintenance)
auth_staff_only = false

# Automatically kill login sessions after this time
;auth_auto_logout = 12h

# Two-factor authentication
two_factor_auth = false

# Configure memory limits for Elasticsearch
# See https://www.elastic.co/guide/en/elasticsearch/reference/6.2/heap-size.html
# Values are in MB. Defaults are:
; elasticsearch_heap_size = 1024
; elasticsearch_memory_limit = 1536

# Add elasticsearch data nodes. They will have the same resources as the master node.
# This number should only be increased. Default is 0. Set with:
elasticsearch_data_node_count = 1

# Configure memory limits for Tika
# The value is in MB. The default is:
;tika_memory_limit = 800
# Configure replication factor for tika.
# The default is 1.
;tika_count = 3


# Configure memory limits for other apps. Use this when you encounter
# "OOM Killed" messages for these services. Start with these doubled
# limits:
;hypothesis_memory_limit = 2048
;nextcloud_memory_limit = 1024

# Rate limits for Hoover API
# The value is "x,y" (x requests every y seconds)
;hoover_ratelimit_user = 30,60

# Configure memory limit for each of Hoover's 3 proxy containers (default 500MB).
# Increase if the proxies OOM when browsing large files:
;hoover_authproxy_memory_limit = 3000

# Configure Let's Encrypt
;[https]
;acme_email = you@yourdomain.bg
;https_port = 443
# Choose from the Let's Encrypt staging or production servers
;acme_caServer = https://acme-v02.api.letsencrypt.org/directory
;acme_caServer = https://acme-staging-v02.api.letsencrypt.org/directory


# Apps that can be enabled or disabled on deploy
;[apps]
;default_app_status = on
;nextcloud = on
;dokuwiki = on
;rocketchat = on


[deploy]
# Enable/disable applications on 'deploy' command. The default value is 'on'.
# 'liquid' and 'hoover' apps are started even if 'default_app_status' was 'off'.
;default_app_status = on

# Health check interval and timeout for all services
# Increase check_interval to lower idle system load at the cost
# of higher deploy times.
check_interval = 16s
check_timeout = 10s

# Configure how to poll health when running `./liquid deploy`
wait_max_sec = 660
wait_poll_interval = 1
wait_green_count = 6


[versions]
# Override versions of docker images
# liquid-core = liquidinvestigations/core:latest


# Run a zipkin tracing system.
; [job:zipkin]
; template = templates/zipkin.nomad

# Run a custom local job, see litterbox.py
# [job:Cat]
# loader = local_jobs.litterbox.Cat

# Hoover Snoop
# - `workers` - count of snoop worker containers
# - `rabbitmq_memory_limit` - memory limit of the queue container, expressed in Mb.
#                             Default 700, increase for larger collections.
# - `postgres_memory_limit` - shared memory limit for postgresql container.
#                             Default 1600, increase for larger collections.
# - `worker_memory_limit` - memory limit of container in Mb; default 400.
# - `worker_process_count` - count of snoop worker processes; default 1.
; [snoop]
; workers = 1
; rabbitmq_memory_limit = 700
; postgres_memory_limit = 1600
; worker_memory_limit = 400
; worker_process_count = 1

# Hoover Collections
# - collection names are [a-z][a-z0-9] only; no underscores or dashes allowed!
# - `sync` - enable periodic re-walking of input data
# Examples below.

# Collection corresponding to nextcloud uploads
; [collection:uploads]
; process = True
; sync = True

# Add the testdata collection. Remove if not needed.
# Be sure to clone it first:
#     git clone https://github.com/liquidinvestigations/testdata collections/testdata
; [collection:testdata]
; process = True


# Continuous Integration
# - drone connected with vault, github auth and docker hub
# - vmck
;[ci]
;runner_capacity = 2
;docker_username = NOTHING
;docker_password = EVERYTHING
;github_client_id = SOMETHING
;github_client_secret = SOMETHING_ELSE
;github_user_filter = username,organization,anything
;docker_registry_address = 10.66.60.1
;docker_registry_port = 6665
